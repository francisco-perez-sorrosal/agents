{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from crewai_tools import (\n",
    "    SerperDevTool,\n",
    "    ScrapeWebsiteTool,\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    "    PDFSearchTool,\n",
    ")\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# NOTE: need to setup a SERPER_API_KEY in the .env file\n",
    "# https://serper.dev/api-key\n",
    "load_dotenv()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "directory_read_tool = DirectoryReadTool(directory='./instructions')\n",
    "file_read_tool = FileReadTool()\n",
    "pdf_search_tool = PDFSearchTool()\n",
    "\n",
    "researcher = Agent(\n",
    "    role=\"Article researcher\",\n",
    "    goal=\"Search in arxhiv.org for a concrete article who's name or description is '{article_description}' and find the URL of the PDF file that allows to download it.\",\n",
    "    backstory=\"You are a researcher who is responsible for finding and downloading articles from arxiv.org on a specific topic.\"\n",
    "              \"The article name or description is: {article_description}.\"\n",
    "              \"You search the web arxiv.org to find the information about the article.\"\n",
    "              \"Search for a link in to the article in PDF format.\"\n",
    "              \"If you find several articles, choose the one that is most relevant to the topic.\"\n",
    "              \"If you cannot find the article, say you didn't found any article related\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    tools=[search_tool, scrape_tool]\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ArticleSearchOutput(BaseModel):\n",
    "    url: str = Field(..., description=\"URL of the PDF file of the article to download\")\n",
    "\n",
    "researcher_task = Task(\n",
    "    description=\"Find in arxiv.org the URL of the PDF file of a concrete article who's name or the description is provided here '{article_description}'\",\n",
    "    expected_output=\"A dictionary with keys 'url' for a URL of the PDF file of the article to download.\",\n",
    "    output_json=ArticleSearchOutput,\n",
    "    agent=researcher,\n",
    ")"
   ],
   "id": "8884b0f70c318460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "article_search_crew = Crew(\n",
    "    agents=[researcher,],\n",
    "    tasks=[researcher_task,],\n",
    "    verbose=True,\n",
    ")"
   ],
   "id": "df834a23840ccb1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_input = {\n",
    "    'article_description': 'HippoRAG insepired long-term memory language models'\n",
    "}"
   ],
   "id": "1ce35184ff32969",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result = article_search_crew.kickoff(inputs=search_input)",
   "id": "8072f02bf187240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(result)",
   "id": "a20137f5f09c2465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "da9399371d72665",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
